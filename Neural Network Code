def Neural_Net(drug, X, lag_size, plots = 0):

    # at this point all drugs have all data for all years, so we can generalize
    df = pd.HDFStore("drugdata.h5")['dat']
    ndc4 = df.loc[df["NDC"]==4]
    ndc4TotalSales = ndc4.groupby('time')['Qty_Ord_(EU)'].sum()
    ndc4Times = ndc4.time.unique()
    ndc4Times = np.array(ndc4Times)
    ndc4Times.sort()
    ndc4TotalSales = np.array(ndc4TotalSales)
    df2 = pd.DataFrame(index=ndc4Times, data=ndc4TotalSales, columns=['sales'])
    dftest = pd.DataFrame(index=ndc4Times[400:], data=ndc4TotalSales[400:], columns=['sales'])
    X = ndc4Times
    Y1 = ndc4TotalSales
    a=10
    #print(a)
    Y_past = [ Y1 ]
    for i in range(a):
        Yi = Y_past[len(Y_past)-1]
        Yi = np.insert(Yi, 0, 0)
        Y_past.append(Yi[0:len(Y1)])
    Y_past = np.matrix(Y_past)    
    
    Y_past = np.delete(Y_past, 0, 0)
    #print("Y: ")
    #print(Y_past)
    Y = Y1
    #print("New shape of Y_past: ")
    Y_past = np.transpose(Y_past)
    #print(Y_past.shape)
    

    #print(X[0])
    Xts = (X - np.datetime64('1970-01-01T00:00:00Z')) / np.timedelta64(1, 's')
    #print(Xts[0])
    Xts = Xts.reshape(Xts.shape[0], 1)
    #print(Xts.shape)
    
    IN = np.hstack((Xts, Y_past))
    #print("Input matrix: ")
    #print(IN)
 
      
    size = int(IN.shape[0]*0.66)
    import random
    t = 0
    #print(size)
    #X_train, X_test = Xts[0:size], Xts[size: len(Xts)]
    X_train, X_test = IN[0:size,:], IN[size:IN.shape[0],:]
    #[X_train, X_test] = np.vsplit(IN, size) ################
    Y_train, Y_test = Y[0:size], Y[size: len(Y)]
    X_train_64, X_test_64 = X[0:size], X[size: len(X)]
    Y_train_64, Y_test_64 = Y[0:size], Y[size: len(Y)]
    
    
    #X_train = X_train.reshape(-1, 1)
    Y_train = Y_train.reshape(-1, 1)
    Y_test = Y_test.reshape(-1, 1)
    

    trainsize = len(IN[size:size,:])
    testsize = len(IN[size:IN.shape[0],:])
    X_train = X_train.astype(float)
    X_test = X_test.astype(float)
    Y_train = Y_train.astype(float)
    Y_test = Y_test.astype(float)
    X_train = np.asarray(X_train)
    X_test = np.asarray(X_test)
    Y_train = np.asarray(Y_train)
    Y_test = np.asarray(Y_test)
    
    from keras.models import Sequential
    from keras.layers import Dense
    from keras.layers import Activation, Dropout, BatchNormalization
    from keras.optimizers import SGD
    model = Sequential()
    model.add(Dense(11, input_dim = 11, kernel_initializer='normal', activation='relu'))
    model.add(Dense(6, kernel_initializer='normal', activation = 'relu'))
    model.add(Dense(6, kernel_initializer='normal', activation = 'relu'))
    model.add(Dense(1, kernel_initializer='normal'))
    model.compile(loss='mae', optimizer='adam')
    
    model.fit(X_train, Y_train, epochs = 200)
    pred_trained = []
    pred = []

    pred_trained = model.predict(X_train)
    pred = model.predict(X_test)
    plt.plot(X_train_64, Y_train, color='green')
    plt.plot(X_train_64, pred_trained, color='red')
    plt.plot(X_test_64, pred, color='orange')
    plt.plot(X_test_64, Y_test, color='blue')
    plt.show()
    print("YTRAIN")
    print(Y_train)
    print("PREDICTIONS TRAINED")
    print(pred_trained)
    print("PREDICTIONS TESTED")
    print(pred)
    error = mean_squared_error(Y_test, pred)
    print("Error: ", error)
    #errors.append(error)
    return();
