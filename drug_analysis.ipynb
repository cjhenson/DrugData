{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 0 - Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-04T19:44:49.382758Z",
     "start_time": "2018-04-04T19:44:41.149633Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as spio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import absolute as nabs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 1 - Load, clean, test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-04T20:34:13.530870Z",
     "start_time": "2018-04-04T20:34:13.495641Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def impmat(fname = 'M_processed.mat', writ = True):\n",
    "    ''' import matlab crap, and turn it to pickles (or return panda df)'''\n",
    "    mat = spio.loadmat(fname, squeeze_me=True)\n",
    "    M = mat['M'] \n",
    "    head = ['time','ndc1','ndc2','ndc3','Trade_Partner_Name',\n",
    "    'Distribution_Center_State','NDC','Distribution_Center_ID_(IC)',\n",
    "    'Distribution_Center_Zip','Eff_Inv_(EU)','Eff_Inv_(PU)',\n",
    "    'Qty_Ord_(EU)','Qty_Ord_(PU)']\n",
    "    # get rid of ndc 1,2,3 because they're pieces of NCD\n",
    "    # also get rid of purchase units, just use eatable\n",
    "    head_adj = [head[0]] + head[4:10] + [head[-2]]\n",
    "    data = pd.DataFrame(M, columns=head)\n",
    "    data[\"time\"] = pd.to_datetime(data[\"time\"], format='%Y%m%d', errors='coerce')\n",
    "\n",
    "    if writ: # h5 allows your variable to be external\n",
    "        dt = pd.HDFStore(\"drugdata.h5\") # don't need to import/export! warning, though: huge\n",
    "        dt['dat'] = data[head_adj] #\n",
    "    return(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-04T20:34:14.191133Z",
     "start_time": "2018-04-04T20:34:13.990992Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def test_hd5(p = 0, q = 0):\n",
    "    \"\"\"test data and run answers to intro quiz\n",
    "    p is to print head of dataframe\n",
    "    q prints quiz answers\n",
    "    doesn't return anything\n",
    "    mostly for access examples\"\"\"\n",
    "    dt = pd.HDFStore(\"drugdata.h5\")[\"dat\"]\n",
    "\n",
    "    header = dt.columns.tolist()\n",
    "    # thanks @brock\n",
    "    def q1(df):\n",
    "        return(df.Trade_Partner_Name.unique())\n",
    "    \n",
    "    def q2(df):\n",
    "        q2 = df.groupby('Trade_Partner_Name')['Distribution_Center_ID_(IC)'].nunique()\n",
    "        q2max = q2.max()\n",
    "        return(q2[q2 == q2max])\n",
    "    \n",
    "    def q3(df):\n",
    "        q3df = df.loc[df[\"time\"].dt.year == 2011] # can also use dt.month\n",
    "        q3TotalSales = q3df.groupby('NDC')['Qty_Ord_(PU)'].sum()\n",
    "        #print(q3TotalSales)\n",
    "        q3sorted = q3TotalSales.sort_values(ascending = False).head()\n",
    "        return(q3sorted)\n",
    "    \n",
    "    def q4(df):\n",
    "        q4 = df['NDC'].value_counts()\n",
    "        NDCLessThan60 = q4[q4 < 60]\n",
    "        if (NDCLessThan60.size == 0):\n",
    "            return(None)\n",
    "        else:\n",
    "            return(NDCLessThan60.size)\n",
    "        \n",
    "    def q5(df):\n",
    "        q5 =  df.groupby('NDC')['Qty_Ord_(PU)'].std()\n",
    "        q5max = q5.max()\n",
    "        NDCHighestVariance = q5[q5 == q5max]\n",
    "        return(NDCHighestVariance)\n",
    "    \n",
    "    def q6(df):\n",
    "        q6 = df.groupby('NDC')['Qty_Ord_(PU)'].nunique()\n",
    "        q6ZeroDemand = q6[q6 == 0]\n",
    "        if (q6ZeroDemand.size == 0):\n",
    "            return(None)\n",
    "        else:\n",
    "            return(q6ZeroDemand.size)\n",
    "    \n",
    "    if p:\n",
    "        for col in header:\n",
    "            print(dt[col].head())\n",
    "    if q:\n",
    "        answers = [q1(dt), q2(dt), q3(dt), q4(dt), q5(dt), q6(dt)]\n",
    "        for i, ans in enumerate(answers):\n",
    "            try:\n",
    "                print('Question %d'%(i+1),  ans)\n",
    "            except:\n",
    "                print('Question %d'%(i+1) + str(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-04T20:34:35.235392Z",
     "start_time": "2018-04-04T20:34:19.533675Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#impmat() # uncomment if never built h5 file\n",
    "test_hd5() # add p=1 or q = 1 to print stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-04T20:34:48.109421Z",
     "start_time": "2018-04-04T20:34:48.098545Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def rem_neg_vals():\n",
    "    ''' if you've just imported from the mat file,\n",
    "    you need to run this to change the neg vals to 0 '''\n",
    "    df = pd.HDFStore(\"drugdata.h5\")[\"dat\"]\n",
    "    # set negative values to 0\n",
    "    df.loc[df['Eff_Inv_(EU)'] < 0,'Eff_Inv_(EU)'] = 0\n",
    "    df.loc[df['Qty_Ord_(EU)'] < 0,'Qty_Ord_(EU)'] = 0\n",
    "    return(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-04T20:34:49.197083Z",
     "start_time": "2018-04-04T20:34:48.793238Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rem_neg_vals()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Early queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-04T22:04:22.336910Z",
     "start_time": "2018-04-04T22:04:22.317143Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def how_many_sales(thr):\n",
    "    ''' in: minimum contributing percentage threshold\n",
    "        out: ID, % of drugs above thr'''\n",
    "    df = pd.HDFStore(\"drugdata.h5\")[\"dat\"]\n",
    "    ind_total = df.groupby('NDC')['Qty_Ord_(EU)'].sum()\n",
    "    sortsales = ind_total.sort_values(ascending = False)\n",
    "    #print(sortsales)\n",
    "    total = sum(ind_total.values)\n",
    "    perc_total = 100 * sortsales / total\n",
    "    clipped_above_total = perc_total[perc_total > thr]\n",
    "    print(len(clipped_above_total), sum(clipped_above_total.values))\n",
    "    return(clipped_above_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-04T22:04:23.037222Z",
     "start_time": "2018-04-04T22:04:22.664257Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 78.4506510137\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NDC\n",
       "55.0     22.399959\n",
       "4.0      16.361364\n",
       "154.0     9.998171\n",
       "109.0     6.040427\n",
       "25.0      5.915590\n",
       "125.0     3.942696\n",
       "7.0       3.572012\n",
       "85.0      3.007674\n",
       "141.0     2.970900\n",
       "62.0      2.224088\n",
       "157.0     2.017771\n",
       "Name: Qty_Ord_(EU), dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "how_many_sales(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-04T22:24:53.281037Z",
     "start_time": "2018-04-04T22:24:53.260128Z"
    }
   },
   "outputs": [],
   "source": [
    "def weeks():\n",
    "    df = pd.HDFStore(\"drugdata.h5\")[\"dat\"]\n",
    "    ## 2008, at least, does indeed have 52 weeks\n",
    "    ## '07 has 27, '17 has 34\n",
    "    for i in range(2007, 2018):\n",
    "        y2k = df.loc[df.time.dt.year == (i)]\n",
    "        wy2k = y2k.groupby(\"time\").nunique()\n",
    "        ly = len(wy2k[\"time\"])\n",
    "        print(i, ly)\n",
    "        if ly != 52:\n",
    "            print(y2k.time.unique())\n",
    "    #print(df.time.nunique()) # 530 unique dates\n",
    "    #print(df.time.unique())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-04T22:25:01.262643Z",
     "start_time": "2018-04-04T22:24:53.467718Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2007 27\n",
      "['2007-07-01T00:00:00.000000000' '2007-07-08T00:00:00.000000000'\n",
      " '2007-07-15T00:00:00.000000000' '2007-07-22T00:00:00.000000000'\n",
      " '2007-07-29T00:00:00.000000000' '2007-08-05T00:00:00.000000000'\n",
      " '2007-08-12T00:00:00.000000000' '2007-08-19T00:00:00.000000000'\n",
      " '2007-08-26T00:00:00.000000000' '2007-09-02T00:00:00.000000000'\n",
      " '2007-09-09T00:00:00.000000000' '2007-09-16T00:00:00.000000000'\n",
      " '2007-09-23T00:00:00.000000000' '2007-09-30T00:00:00.000000000'\n",
      " '2007-10-21T00:00:00.000000000' '2007-10-28T00:00:00.000000000'\n",
      " '2007-11-11T00:00:00.000000000' '2007-11-18T00:00:00.000000000'\n",
      " '2007-11-25T00:00:00.000000000' '2007-12-02T00:00:00.000000000'\n",
      " '2007-12-09T00:00:00.000000000' '2007-12-16T00:00:00.000000000'\n",
      " '2007-12-23T00:00:00.000000000' '2007-12-30T00:00:00.000000000'\n",
      " '2007-10-07T00:00:00.000000000' '2007-10-14T00:00:00.000000000'\n",
      " '2007-11-04T00:00:00.000000000']\n",
      "2008 52\n",
      "2009 52\n",
      "2010 52\n",
      "2011 52\n",
      "2012 53\n",
      "['2012-09-16T00:00:00.000000000' '2012-09-09T00:00:00.000000000'\n",
      " '2012-09-02T00:00:00.000000000' '2012-08-26T00:00:00.000000000'\n",
      " '2012-08-19T00:00:00.000000000' '2012-08-12T00:00:00.000000000'\n",
      " '2012-04-22T00:00:00.000000000' '2012-04-29T00:00:00.000000000'\n",
      " '2012-05-06T00:00:00.000000000' '2012-05-13T00:00:00.000000000'\n",
      " '2012-05-20T00:00:00.000000000' '2012-05-27T00:00:00.000000000'\n",
      " '2012-01-15T00:00:00.000000000' '2012-01-22T00:00:00.000000000'\n",
      " '2012-01-29T00:00:00.000000000' '2012-02-05T00:00:00.000000000'\n",
      " '2012-02-12T00:00:00.000000000' '2012-02-19T00:00:00.000000000'\n",
      " '2012-02-26T00:00:00.000000000' '2012-03-04T00:00:00.000000000'\n",
      " '2012-10-21T00:00:00.000000000' '2012-10-14T00:00:00.000000000'\n",
      " '2012-10-07T00:00:00.000000000' '2012-12-30T00:00:00.000000000'\n",
      " '2012-07-15T00:00:00.000000000' '2012-07-22T00:00:00.000000000'\n",
      " '2012-09-30T00:00:00.000000000' '2012-09-23T00:00:00.000000000'\n",
      " '2012-12-02T00:00:00.000000000' '2012-11-25T00:00:00.000000000'\n",
      " '2012-11-18T00:00:00.000000000' '2012-11-11T00:00:00.000000000'\n",
      " '2012-11-04T00:00:00.000000000' '2012-10-28T00:00:00.000000000'\n",
      " '2012-08-05T00:00:00.000000000' '2012-07-29T00:00:00.000000000'\n",
      " '2012-12-23T00:00:00.000000000' '2012-06-03T00:00:00.000000000'\n",
      " '2012-06-10T00:00:00.000000000' '2012-06-17T00:00:00.000000000'\n",
      " '2012-06-24T00:00:00.000000000' '2012-07-01T00:00:00.000000000'\n",
      " '2012-12-16T00:00:00.000000000' '2012-12-09T00:00:00.000000000'\n",
      " '2012-01-01T00:00:00.000000000' '2012-01-08T00:00:00.000000000'\n",
      " '2012-07-08T00:00:00.000000000' '2012-03-11T00:00:00.000000000'\n",
      " '2012-03-18T00:00:00.000000000' '2012-03-25T00:00:00.000000000'\n",
      " '2012-04-01T00:00:00.000000000' '2012-04-08T00:00:00.000000000'\n",
      " '2012-04-15T00:00:00.000000000']\n",
      "2013 52\n",
      "2014 52\n",
      "2015 52\n",
      "2016 52\n",
      "2017 34\n",
      "['2017-04-30T00:00:00.000000000' '2017-04-23T00:00:00.000000000'\n",
      " '2017-04-02T00:00:00.000000000' '2017-05-21T00:00:00.000000000'\n",
      " '2017-03-05T00:00:00.000000000' '2017-01-15T00:00:00.000000000'\n",
      " '2017-01-22T00:00:00.000000000' '2017-02-12T00:00:00.000000000'\n",
      " '2017-03-26T00:00:00.000000000' '2017-05-14T00:00:00.000000000'\n",
      " '2017-02-26T00:00:00.000000000' '2017-05-07T00:00:00.000000000'\n",
      " '2017-03-12T00:00:00.000000000' '2017-02-05T00:00:00.000000000'\n",
      " '2017-02-19T00:00:00.000000000' '2017-04-16T00:00:00.000000000'\n",
      " '2017-04-09T00:00:00.000000000' '2017-07-02T00:00:00.000000000'\n",
      " '2017-03-19T00:00:00.000000000' '2017-07-09T00:00:00.000000000'\n",
      " '2017-01-08T00:00:00.000000000' '2017-01-29T00:00:00.000000000'\n",
      " '2017-01-01T00:00:00.000000000' '2017-07-16T00:00:00.000000000'\n",
      " '2017-07-23T00:00:00.000000000' '2017-08-13T00:00:00.000000000'\n",
      " '2017-08-20T00:00:00.000000000' '2017-06-18T00:00:00.000000000'\n",
      " '2017-06-25T00:00:00.000000000' '2017-07-30T00:00:00.000000000'\n",
      " '2017-08-06T00:00:00.000000000' '2017-05-28T00:00:00.000000000'\n",
      " '2017-06-04T00:00:00.000000000' '2017-06-11T00:00:00.000000000']\n"
     ]
    }
   ],
   "source": [
    "weeks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - The meaty bits!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: [  4.  20.   2.   3.  21.  15.  12.   9.   5.  14.   0.  22.  26.  27.   8.\n",
      "  24.  10.  13.  11.  16.   7.  19.  23.  17.  25.   6.   1.  18.]\n"
     ]
    }
   ],
   "source": [
    "def sales(df, t, co):\n",
    "    \"\"\"in: df=data object, t=time of interest, co=partner, \n",
    "    want to return the list of sales per location\"\"\"\n",
    "    q3df = df.loc[df[\"time\"].dt.week = t] # can also use dt.month\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-04T21:33:30.565395Z",
     "start_time": "2018-04-04T21:33:30.542991Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def smape(f, d):\n",
    "    ''' symmetric mean absolute percentage error\n",
    "    in: vectors f = y_hat, d = y \n",
    "    out: the smape, yo '''\n",
    "    n = len(f)\n",
    "    num = np.sum(nabs(f - d))\n",
    "    denom = np.sum(nabs(f) + nabs(d))\n",
    "    return((1/n) * num/denom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    dt = pd.HDFStore(\"drugdata.h5\")[\"dat\"]\n",
    "    start_date = pd.to_datetime(\"20110101\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
